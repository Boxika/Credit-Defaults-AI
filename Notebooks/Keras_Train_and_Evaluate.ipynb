{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Keras(TensorFlow) Training and Evaluation Notebook\n",
        "\n",
        "This notebook documents the training and evaluation of a Keras model for predicting credit default using the Default of Credit Card Clients Dataset. Keras, which runs on top of TensorFlow, is a powerful deep learning library that allows for easy and fast prototyping, making it ideal for building neural networks."
      ],
      "metadata": {
        "id": "m-mJYiMp0-p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of Dependencies\n",
        "\n",
        "This will load all libraries necessary to run the script."
      ],
      "metadata": {
        "id": "AOv6LlRI8U_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas scikit-learn imblearn tensorflow keras joblib scikeras\n"
      ],
      "metadata": {
        "id": "oK2NX9bZ8UOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import os"
      ],
      "metadata": {
        "id": "L0Gcuvco8mob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preprocessing Data\n",
        "\n",
        "The dataset is accessed from Google Drive, and subsequent steps ensure that the data is preprocessed appropriately, particularly addressing class imbalance and splitting the data into training and test sets."
      ],
      "metadata": {
        "id": "MiYDo8gNcHxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/drive/My Drive/VCRK Credit Defaults/Datasets/UCI_Credit_Card.csv'  # Update this path to your file location in Google Drive\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop(columns=['default.payment.next.month'])\n",
        "y = data['default.payment.next.month']\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf2k7GpvcaiM",
        "outputId": "eb95d83d-ac62-46bc-8539-fb6c4d4ac25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning and Model Definition\n",
        "\n",
        "This code snippet demonstrates building, scaling, and hyperparameter tuning a Keras (TensorFlow) neural network model. To avoid issues with multiprocessing in a multithreaded environment, it sets environment variables. The data is then scaled using StandardScaler to normalize the features, ensuring the input data has zero mean and unit variance. The create_model function defines a neural network model with three hidden layers, each followed by a dropout layer to prevent overfitting. The model uses the Adam optimizer, binary cross-entropy loss, and tracks accuracy. Hyperparameter tuning is performed using RandomizedSearchCV, which tests different combinations of hyperparameters such as optimizer, activation function, dropout rate, batch size, and epochs. The best set of hyperparameters is identified and printed, optimizing the model's performance."
      ],
      "metadata": {
        "id": "-uEfYeiqct-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import uniform, randint\n",
        "import os\n",
        "\n",
        "# Avoid fork issues with multithreading\n",
        "os.environ['JOBLIB_MULTIPROCESSING'] = '0'\n",
        "os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp'\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define a function to create the model\n",
        "def create_model(input_dim, optimizer='adam', activation='relu', dropout_rate=0.5, l2_reg=0.001):\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=input_dim, activation=activation, kernel_regularizer=l2(l2_reg)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(64, activation=activation, kernel_regularizer=l2(l2_reg)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(32, activation=activation, kernel_regularizer=l2(l2_reg)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning function\n",
        "def hyperparameter_tuning(X_train, y_train, input_dim):\n",
        "    model = KerasClassifier(model=create_model, input_dim=input_dim, verbose=0)\n",
        "\n",
        "    param_dist = {\n",
        "        'model__optimizer': ['adam', 'rmsprop'],\n",
        "        'model__activation': ['relu', 'tanh'],\n",
        "        'model__dropout_rate': uniform(0.3, 0.4),  # This will sample between 0.3 and 0.7\n",
        "        'batch_size': randint(32, 129),  # This will sample between 32 and 128\n",
        "        'epochs': randint(50, 150)  # This will sample between 50 and 150\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, n_jobs=1, cv=3, random_state=42)\n",
        "    random_search_result = random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Summarize the results\n",
        "    print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n",
        "    return random_search_result.best_params_\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "best_params = hyperparameter_tuning(X_train, y_train, X_train.shape[1])\n"
      ],
      "metadata": {
        "id": "VlITaSErcyQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Best Model\n",
        "\n",
        "The best parameters for the optimizer, activation function, dropout rate, L2 regularization, batch size, and epochs are extracted from the best_params dictionary. Using these parameters, a new model is created with the create_model function, tailored to the specific input dimensions of the training data. The model is then trained using the training data, with early stopping configured to monitor the validation loss and stop training if it doesn't improve for 10 consecutive epochs, restoring the best weights observed during training. The training history is recorded for further analysis."
      ],
      "metadata": {
        "id": "nVNm9XV_PCcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best parameters\n",
        "best_optimizer = best_params['model__optimizer']\n",
        "best_activation = best_params['model__activation']\n",
        "best_dropout_rate = best_params['model__dropout_rate']\n",
        "best_l2_reg = best_params['model__l2_reg']\n",
        "best_batch_size = best_params['batch_size']\n",
        "best_epochs = best_params['epochs']\n",
        "\n",
        "# Create the model with the best parameters\n",
        "best_model = create_model(input_dim=X_train.shape[1], optimizer=best_optimizer, activation=best_activation, dropout_rate=best_dropout_rate, l2_reg=best_l2_reg)\n",
        "\n",
        "# Train the best model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = best_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=best_epochs, batch_size=best_batch_size, callbacks=[early_stopping], verbose=1)\n"
      ],
      "metadata": {
        "id": "LG_d4Ogg3YZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "This code snippet evaluates the performance of a trained Keras model on validation and test datasets using key metrics and visualizations. It prints the classification report, confusion matrix, and ROC-AUC score for both datasets and plots the ROC curve for the test set."
      ],
      "metadata": {
        "id": "H7rEpoMrDE4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluate on validation data\n",
        "y_val_pred_proba = best_model.predict(X_val).ravel()\n",
        "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(\"Validation Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))\n",
        "print(f\"Validation ROC-AUC Score: {roc_auc_score(y_val, y_val_pred_proba):.4f}\")\n",
        "\n",
        "# Evaluate on test data\n",
        "y_test_pred_proba = best_model.predict(X_test).ravel()\n",
        "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(f\"Test ROC-AUC Score: {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
        "\n",
        "# Plot ROC curve for test data\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.4f)' % roc_auc_score(y_test, y_test_pred_proba))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2uHCVHXE9TJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model\n",
        "\n",
        "This is used to save the best model after training and evaluation."
      ],
      "metadata": {
        "id": "d-gHPCgqQbrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the scaler\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "print(\"Scaler saved to scaler.joblib\")\n",
        "\n",
        "# Save the model\n",
        "best_model.save('keras_model.h5')\n",
        "print(\"Model saved to keras_model.h5\")\n"
      ],
      "metadata": {
        "id": "DdwpPpUE7dnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we trained and evaluated a Keras (TensorFlow) model for credit default prediction. The model was trained using SMOTE to handle class imbalance. The evaluation showed promising results with a high ROC-AUC score.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Experiment with different neural network architectures and hyperparameters to improve model performance.\n",
        "- Try different machine learning models and compare their performance.\n",
        "- Deploy the model using a Flask API for real-time predictions."
      ],
      "metadata": {
        "id": "t_lZnYqWQl43"
      }
    }
  ]
}