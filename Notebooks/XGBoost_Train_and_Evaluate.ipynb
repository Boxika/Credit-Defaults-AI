{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMik9A3J/qkO4kvH8cdjufJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boxika/Credit-Defaults-AI/blob/main/Notebooks/XGBoost_Train_and_Evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Training and Evaluation Notebook\n",
        "This notebook documents the training and evaluation of an XGBoost model for predicting credit default using the Default of Credit Card Clients Dataset."
      ],
      "metadata": {
        "id": "HzuRPz9Veq6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of Dependencies\n",
        "This will load all the libraries necessary to run the script"
      ],
      "metadata": {
        "id": "tNSfgYW9gN9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas xgboost scikit-learn imblearn joblib"
      ],
      "metadata": {
        "id": "vj2od94ngbRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4xs7IsXjgWml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preprocessing the Data\n",
        "The dataset is accessed from Google Drive, and subsequent steps ensure that the data is preprocessed appropriately, particularly addressing class imbalance and splitting the data into training, validation, and test sets."
      ],
      "metadata": {
        "id": "HS1DV-kQgeJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/UCI_Credit_Card.csv'  # Update this path if needed\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Assume 'default.payment.next.month' is the target variable and features are all other columns\n",
        "X = data.drop(columns=['default.payment.next.month'])\n",
        "y = data['default.payment.next.month']\n",
        "\n",
        "# Apply SMOTE to handle class imbalance\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "2ab7vovGgj9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "The code cell demonstrates hyperparameter tuning and training of an XGBoost classifier using grid search. It involves defining a parameter grid, initializing the XGBoost model, and running GridSearchCV for optimization. The parameter grid specifies values for alpha, reg_lambda, learning_rate, max_depth, n_estimators, and scale_pos_weight. The model is fit with the best parameters identified by GridSearchCV, and the best estimator is further trained with early stopping using a validation set. The best parameters and AUC score are printed.\n"
      ],
      "metadata": {
        "id": "5Tbl1CWKg-4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5,],\n",
        "    'reg_lambda': [1, 10,],\n",
        "    'learning_rate': [0.01, 0.1,],\n",
        "    'max_depth': [3, 4,],\n",
        "    'n_estimators': [100, 200],\n",
        "    'scale_pos_weight': [1, 2, 2.5]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    random_state=42,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best AUC score: \", grid_search.best_score_)\n",
        "\n",
        "# Train the best model with early stopping\n",
        "best_xgb_clf = grid_search.best_estimator_\n",
        "best_xgb_clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='auc',\n",
        "    early_stopping_rounds=10,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "XoPEWQJ3hAf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "The code cell evaluates the performance of the best XGBoost classifier on training, validation, and test datasets. It starts by predicting the labels and probabilities for the training data and then prints the classification report, confusion matrix, and ROC-AUC score. The same evaluation steps are repeated for the validation and test datasets. Additionally, it plots the ROC curve for the test data, displaying the trade-off between the true positive rate and false positive rate, along with the ROC-AUC score. This evaluation helps in understanding the model's performance across different data splits."
      ],
      "metadata": {
        "id": "q_qG11rKhG96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on training data\n",
        "y_train_pred = best_xgb_clf.predict(X_train)\n",
        "y_train_pred_proba = best_xgb_clf.predict_proba(X_train)[:, 1]\n",
        "\n",
        "print(\"Training Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "print(f\"Training ROC-AUC Score: {roc_auc_score(y_train, y_train_pred_proba):.4f}\")\n",
        "\n",
        "# Evaluate on validation data\n",
        "y_val_pred = best_xgb_clf.predict(X_val)\n",
        "y_val_pred_proba = best_xgb_clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(\"Validation Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))\n",
        "print(f\"Validation ROC-AUC Score: {roc_auc_score(y_val, y_val_pred_proba):.4f}\")\n",
        "\n",
        "# Evaluate on test data\n",
        "y_test_pred = best_xgb_clf.predict(X_test)\n",
        "y_test_pred_proba = best_xgb_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(f\"Test ROC-AUC Score: {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
        "\n",
        "# Plot ROC curve for test data\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.4f)' % roc_auc_score(y_test, y_test_pred_proba))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ssMoNiahRWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model\n",
        "\n",
        "The code saves the trained XGBoost model to a file named 'best_xgb_model.joblib' using the `joblib` library."
      ],
      "metadata": {
        "id": "4_Qubs4Lhfip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(best_xgb_clf, 'best_xgb_model.joblib')\n",
        "print(\"Model saved to best_xgb_model.joblib\")\n"
      ],
      "metadata": {
        "id": "B39YEP_6hh4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we trained and evaluated an XGBoost model for credit default prediction. The model was trained using SMOTE to handle class imbalance and hyperparameter tuning was performed using GridSearchCV. The evaluation showed promising results with a high ROC-AUC score.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Experiment with different feature engineering techniques to improve model performance.\n",
        "- Try different machine learning models and compare their performance.\n",
        "- Deploy the model using a Flask API for real-time predictions.\n"
      ],
      "metadata": {
        "id": "XK1KCErWhl-Q"
      }
    }
  ]
}